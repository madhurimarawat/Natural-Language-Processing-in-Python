{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Experiment 3\n",
        "## Demonstrate a Bigram Language Model."
      ],
      "metadata": {
        "id": "H5oK6YAmRYDB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## N-gram Model\n",
        "In natural language processing n-gram is a contiguous sequence of n items generated from a given sample of text where the items can be characters or words and n can be any numbers like 1,2,3, etc.\n",
        "\n",
        "For example, let us consider a line – “Either my way or no way”, so below is the possible n-gram models that we can generate –\n",
        "<br><br>\n",
        "\n",
        "<img src = \"https://b2611031.smushcdn.com/2611031/wp-content/uploads/2021/04/n-grams-696x195.png?lossy=0&strip=1&webp=1\">\n",
        "\n",
        "<br>\n",
        "\n",
        "As we can see using the n-gram model we can generate all possible contiguous combinations of length n for the words in the sentence. When n=1, the n-gram model resulted in one word in each tuple. When n=2, it generated 5 combinations of sequences of length 2, and so on.\n",
        "\n",
        "Similarly for a given word we can generate n-gram model to create sequential combinations of length n for characters in the word. For example from the sequence of characters “Afham”, a 3-gram model will be generated as “Afh”, “fha”, “ham”, and so on.\n",
        "\n",
        "Due to their frequent uses, n-gram models for n=1,2,3 have specific names as Unigram, Bigram, and Trigram models respectively.\n",
        "\n",
        "Use of n-grams in NLP\n",
        "N-Grams are useful to create features from text corpus for machine learning algorithms like SVM, Naive Bayes, etc.\n",
        "N-Grams are useful for creating capabilities like autocorrect, autocompletion of sentences, text summarization, speech recognition, etc.\n"
      ],
      "metadata": {
        "id": "mVnaZLSbS7TY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Unigrams or 1-grams  \n",
        "To generate 1-grams we pass the value of n=1 in ngrams function of NLTK. But first, we split the sentence into tokens and then pass these tokens to ngrams function.\n",
        "\n",
        "As we can see we have got one word in each tuple for the Unigram model."
      ],
      "metadata": {
        "id": "1Nb1mQ7mUc9g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.util import ngrams\n",
        "\n",
        "n = 1\n",
        "sentence = 'You will face many defeats in life, but never let yourself be defeated.'\n",
        "unigrams = ngrams(sentence.split(), n)\n",
        "\n",
        "print(\"Unigram Model is:\\n\")\n",
        "\n",
        "for item in unigrams:\n",
        "    print(item)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ttKibwHXUhhf",
        "outputId": "e56e65ab-052d-4676-e145-224a07b06178"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unigram Model is:\n",
            "\n",
            "('You',)\n",
            "('will',)\n",
            "('face',)\n",
            "('many',)\n",
            "('defeats',)\n",
            "('in',)\n",
            "('life,',)\n",
            "('but',)\n",
            "('never',)\n",
            "('let',)\n",
            "('yourself',)\n",
            "('be',)\n",
            "('defeated.',)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bigrams or 2-grams\n",
        "## Implementing Bigram Model\n",
        "## If it is used for Predicting two words it is called Bigram Model.\n",
        "\n",
        "For generating 2-grams we pass the value of n=2 in ngrams function of NLTK. But first, we split the sentence into tokens and then pass these tokens to ngrams function.\n",
        "\n",
        "As we can see we have got two adjacent words in each tuple in our Bigrams model."
      ],
      "metadata": {
        "id": "bv7QqOH4TexI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxMdVmouRIcw",
        "outputId": "a8496ef2-57e8-40e8-b7b1-4942640e6522"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bigram Model is:\n",
            "\n",
            "('The', 'purpose')\n",
            "('purpose', 'of')\n",
            "('of', 'our')\n",
            "('our', 'life')\n",
            "('life', 'is')\n",
            "('is', 'to')\n",
            "('to', 'happy')\n"
          ]
        }
      ],
      "source": [
        "# Importing Required function from Library\n",
        "from nltk.util import ngrams\n",
        "\n",
        "n = 2\n",
        "sentence = 'The purpose of our life is to happy'\n",
        "bigrams = ngrams(sentence.split(), n)\n",
        "\n",
        "print(\"Bigram Model is:\\n\")\n",
        "\n",
        "for item in bigrams:\n",
        "    print(item)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiment 4\n",
        "## Demonstrate a Trigram Language Model."
      ],
      "metadata": {
        "id": "ih1gLhhHVh5G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trigrams or 3-grams\n",
        "## Implementing Trigram Model\n",
        "## In case of 3-grams, we pass the value of n=3 in ngrams function of NLTK. But first, we split the sentence into tokens and then pass these tokens to ngrams function.\n",
        "\n",
        "As we can see we have got three words in each tuple for the Trigram model."
      ],
      "metadata": {
        "id": "-4G02UrLVAQB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.util import ngrams\n",
        "\n",
        "n = 3\n",
        "sentence = 'Whoever is happy will make others happy too'\n",
        "trigrams = ngrams(sentence.split(), n)\n",
        "\n",
        "print(\"Trigram Model is:\\n\")\n",
        "\n",
        "for item in trigrams:\n",
        "    print(item)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pWdw1QuMUPaD",
        "outputId": "d8a70b62-6e93-499f-9808-57175c3efcd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trigram Model is:\n",
            "\n",
            "('Whoever', 'is', 'happy')\n",
            "('is', 'happy', 'will')\n",
            "('happy', 'will', 'make')\n",
            "('will', 'make', 'others')\n",
            "('make', 'others', 'happy')\n",
            "('others', 'happy', 'too')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-dvLXbAuVUUP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}