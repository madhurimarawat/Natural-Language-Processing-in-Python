{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Experiment 6\n",
        "## Perform Lemmatization."
      ],
      "metadata": {
        "id": "o-zuCGDd62Jn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lemmatization is a linguistic process that reduces words to their base or root form, aiding text analysis. It's crucial in Natural Language Processing (NLP), distinguishing words based on their grammatical category (e.g., nouns, verbs). Lemmatizers generate lemmata, the base forms of words, simplifying language analysis for tasks like sentiment analysis and information retrieval."
      ],
      "metadata": {
        "id": "gs-cOouhpOqC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing Library\n",
        "import nltk\n",
        "\n",
        "# Importing Lemmatizer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# Downloading wordnet\n",
        "# WordNet is a lexical database of semantic relations between words that links words into semantic relations including synonyms, hyponyms, and meronyms.\n",
        "# It is a large lexical database of English, where nouns, verbs, adjectives, and adverbs are grouped into sets of cognitive synonyms (synsets), each expressing a distinct concept.\n",
        "# Synsets are interlinked by means of conceptual-semantic and lexical relations. The resulting network of meaningfully related words and concepts can be navigated with the browser.\n",
        "# WordNetâ€™s structure makes it a useful tool for computational linguistics and natural language processing .\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Initializing object of Lemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# List of words\n",
        "words = ['cats', 'cat', 'study', 'studies', 'run','runs']\n",
        "\n",
        "print(\"Words after Lemmatizing:\")\n",
        "\n",
        "# Iterating over list and converting to lemma using Lemmatizer\n",
        "for word in words:\n",
        "\n",
        "    # Converting to base word/lemma\n",
        "    lemma = lemmatizer.lemmatize(word)\n",
        "    print(f\"{word} -> {lemma}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rh3Bji3U65s2",
        "outputId": "4ca69bb9-ecc4-4677-f4c7-a09957898643"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Words after Lemmatizing:\n",
            "cats -> cat\n",
            "cat -> cat\n",
            "study -> study\n",
            "studies -> study\n",
            "run -> run\n",
            "runs -> run\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V7MdmA2-7te7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}