{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Experiment 10\n",
        "## Build a Chunker."
      ],
      "metadata": {
        "id": "n3qDPZthQ2He"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Chunking in Natural Language Processing (NLP) - Markdown Explanation with Output:**\n",
        "\n",
        "```python\n",
        "import nltk\n",
        "from nltk.chunk import RegexpParser\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Sample sentence\n",
        "sentence = \"The cat sat on the mat.\"\n",
        "\n",
        "# Tokenize the sentence\n",
        "words = word_tokenize(sentence)\n",
        "\n",
        "# Perform POS tagging\n",
        "pos_tags = nltk.pos_tag(words)\n",
        "\n",
        "# Define chunking patterns using regular expressions\n",
        "chunking_patterns = r\"\"\"\n",
        "    NP: {<DT>?<JJ>*<NN>}   # chunk determiner/possessive, adjectives, and noun\n",
        "    PP: {<IN><NP>}         # chunk prepositions followed by NP\n",
        "    VP: {<VB.*><NP|PP>*}   # chunk verbs and their arguments\n",
        "\"\"\"\n",
        "\n",
        "# Create a chunk parser using the defined patterns\n",
        "chunk_parser = RegexpParser(chunking_patterns)\n",
        "\n",
        "# Apply chunking to the POS-tagged words\n",
        "chunks = chunk_parser.parse(pos_tags)\n",
        "\n",
        "# Display the chunks\n",
        "print(chunks)\n",
        "```\n",
        "\n",
        "**Output:**\n",
        "```\n",
        "(S\n",
        "  (NP The/DT cat/NN)\n",
        "  (VP sat/VBD (PP on/IN (NP the/DT mat/NN)))\n",
        "  ./.)\n",
        "```\n",
        "\n",
        "In the output, the sentence is parsed into a tree structure, where:\n",
        "- **NP (Noun Phrase):** \"The cat\"\n",
        "- **VP (Verb Phrase):** \"sat on the mat\"\n",
        "- **PP (Prepositional Phrase):** \"on the mat\"\n",
        "\n",
        "Each phrase is structured hierarchically, providing a syntactic representation of the sentence's components based on the defined chunking patterns."
      ],
      "metadata": {
        "id": "4GzKEEIdQ67m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Explanation of Code\n",
        "\n",
        "1. **Import Libraries and Download Data:**\n",
        "   - Import necessary libraries including NLTK modules and download required data.\n",
        "\n",
        "2. **Load and Train POS Tagger:**\n",
        "   - Load the Penn Treebank corpus for training.\n",
        "   - Train a POS tagger using a combination of a default tagger for unknown words and an Unigram tagger.\n",
        "\n",
        "3. **Tokenize and Tag Sample Sentence:**\n",
        "   - Tokenize the sample sentence into words.\n",
        "   - Use the trained POS tagger to tag the words in the sample sentence.\n",
        "\n",
        "4. **Define Chunk Grammar:**\n",
        "   - Define a regular expression-based chunk grammar.\n",
        "   - NP (Noun Phrase): Sequences of determiners (DT), adjectives (JJ), and nouns (NN).\n",
        "   - VP (Verb Phrase): Verbs (VB) and their associated noun phrases (NP) or prepositional phrases (PP).\n",
        "\n",
        "5. **Create Chunk Parser:**\n",
        "   - Create a chunk parser using the defined regular expression-based grammar.\n",
        "\n",
        "6. **Apply Chunk Parser:**\n",
        "   - Apply the chunk parser to the POS-tagged sentence, creating a tree structure representing the chunks.\n",
        "\n",
        "7. **Visualize and Print Tree Structure:**\n",
        "   - Optionally, visualize the resulting tree structure.\n",
        "   - Print the tree structure using the `pretty_print()` method.\n",
        "\n",
        "This code demonstrates chunking based on a regular expression grammar, identifying and grouping noun phrases (NP) and verb phrases (VP) in the sample sentence. The resulting tree structure illustrates the identified chunks in the sentence."
      ],
      "metadata": {
        "id": "j6lZxNiZRqXC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ib87wC-1oeNR",
        "outputId": "041d199a-ef8b-4a73-8f32-eac06ab0ccd1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Package treebank is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                               S                                              \n",
            "    ___________________________|__________________________________________     \n",
            "   |     |            NP               NP      NP            NP           NP  \n",
            "   |     |     _______|________        |       |        _____|_____       |    \n",
            "over/IN ./. The/DT quick/JJ brown/NN fox/NN jumps/NN the/DT     lazy/NN dog/NN\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk import RegexpParser\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import treebank\n",
        "\n",
        "# Download the NLTK data (you only need to do this once)\n",
        "nltk.download('punkt')\n",
        "nltk.download('treebank')\n",
        "\n",
        "# Load a pre-trained POS tagger\n",
        "tagged_sentences = treebank.tagged_sents()\n",
        "train_data = tagged_sentences[:3000]\n",
        "pos_tagger = nltk.DefaultTagger('NN')  # Default tagger for unknown words\n",
        "pos_tagger = nltk.UnigramTagger(train_data, backoff=pos_tagger)\n",
        "\n",
        "# Define a sample sentence\n",
        "sample_sentence = \"The quick brown fox jumps over the lazy dog.\"\n",
        "\n",
        "# Tokenize and tag the sample sentence\n",
        "tokens = word_tokenize(sample_sentence)\n",
        "pos_tags = pos_tagger.tag(tokens)\n",
        "\n",
        "# Define a regular expression-based chunk grammar\n",
        "chunk_grammar = r\"\"\"\n",
        "    NP: {<DT>?<JJ>*<NN>}   # Chunk sequences of DT, JJ, and NN\n",
        "    VP: {<VB.*><NP|PP>*}   # Chunk verbs and their arguments\n",
        "\"\"\"\n",
        "\n",
        "# Create a chunk parser using the regular expression-based grammar\n",
        "chunk_parser = RegexpParser(chunk_grammar)\n",
        "\n",
        "# Apply the chunk parser to the POS-tagged sentence\n",
        "tree = chunk_parser.parse(pos_tags)\n",
        "\n",
        "# Visualize the resulting tree (optional)\n",
        "\n",
        "# Print the tree structure\n",
        "tree.pretty_print()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ATXFSAR2orEp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}