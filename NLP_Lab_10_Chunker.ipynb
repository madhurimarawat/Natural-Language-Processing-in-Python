{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Experiment 10\n",
        "## Build a Chunker."
      ],
      "metadata": {
        "id": "n3qDPZthQ2He"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A chunker, in the context of natural language processing (NLP), is a program or algorithm that identifies and segments syntactic units (chunks) in a sentence. These chunks typically consist of words that form a meaningful unit, such as noun phrases, verb phrases, or prepositional phrases.\n",
        "\n",
        "The process of chunking involves dividing a sentence into chunks based on the grammatical structure and relationships between words. It's an intermediate step between part-of-speech tagging and full parsing. While part-of-speech tagging assigns a part-of-speech label to each word in a sentence, chunking goes a step further by grouping words into meaningful units.\n",
        "\n",
        "Here's an example to illustrate chunking:\n",
        "\n",
        "**Sentence:** \"The black cat sat on the windowsill.\"\n",
        "\n",
        "**Part-of-Speech Tagging:**\n",
        "```\n",
        "The/DT black/JJ cat/NN sat/VBD on/IN the/DT windowsill/NN ./.\n",
        "```\n",
        "\n",
        "**Chunking Result:**\n",
        "```\n",
        "[The black cat] [sat] [on the windowsill].\n",
        "```\n",
        "\n",
        "In this example, the chunker identifies and groups the words into three chunks: a noun phrase (\"The black cat\"), a verb (\"sat\"), and a prepositional phrase (\"on the windowsill\").\n",
        "\n",
        "Chunking is often used in various NLP applications, including information extraction, named entity recognition, and shallow parsing. Different techniques and tools can be employed for chunking, such as regular expressions, rule-based systems, or machine learning approaches."
      ],
      "metadata": {
        "id": "4wcATIQT_vGF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Chunking in Natural Language Processing (NLP) - Explanation with Output:**\n",
        "\n",
        "```python\n",
        "import nltk\n",
        "from nltk.chunk import RegexpParser\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Sample sentence\n",
        "sentence = \"The cat sat on the mat.\"\n",
        "\n",
        "# Tokenize the sentence\n",
        "words = word_tokenize(sentence)\n",
        "\n",
        "# Perform POS tagging\n",
        "pos_tags = nltk.pos_tag(words)\n",
        "\n",
        "# Define chunking patterns using regular expressions\n",
        "chunking_patterns = r\"\"\"\n",
        "    NP: {<DT>?<JJ>*<NN>}   # chunk determiner/possessive, adjectives, and noun\n",
        "    PP: {<IN><NP>}         # chunk prepositions followed by NP\n",
        "    VP: {<VB.*><NP|PP>*}   # chunk verbs and their arguments\n",
        "\"\"\"\n",
        "\n",
        "# Create a chunk parser using the defined patterns\n",
        "chunk_parser = RegexpParser(chunking_patterns)\n",
        "\n",
        "# Apply chunking to the POS-tagged words\n",
        "chunks = chunk_parser.parse(pos_tags)\n",
        "\n",
        "# Display the chunks\n",
        "print(chunks)\n",
        "```\n",
        "\n",
        "**Output:**\n",
        "```\n",
        "(S\n",
        "  (NP The/DT cat/NN)\n",
        "  (VP sat/VBD (PP on/IN (NP the/DT mat/NN)))\n",
        "  ./.)\n",
        "```\n",
        "\n",
        "In the output, the sentence is parsed into a tree structure, where:\n",
        "- **NP (Noun Phrase):** \"The cat\"\n",
        "- **VP (Verb Phrase):** \"sat on the mat\"\n",
        "- **PP (Prepositional Phrase):** \"on the mat\"\n",
        "\n",
        "Each phrase is structured hierarchically, providing a syntactic representation of the sentence's components based on the defined chunking patterns."
      ],
      "metadata": {
        "id": "4GzKEEIdQ67m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Explanation of Code\n",
        "\n",
        "1. **Import Libraries and Download Data:**\n",
        "   - Import necessary libraries including NLTK modules and download required data.\n",
        "\n",
        "2. **Load and Train POS Tagger:**\n",
        "   - Load the Penn Treebank corpus for training.\n",
        "   - Train a POS tagger using a combination of a default tagger for unknown words and an Unigram tagger.\n",
        "\n",
        "3. **Tokenize and Tag Sample Sentence:**\n",
        "   - Tokenize the sample sentence into words.\n",
        "   - Use the trained POS tagger to tag the words in the sample sentence.\n",
        "\n",
        "4. **Define Chunk Grammar:**\n",
        "   - Define a regular expression-based chunk grammar.\n",
        "   - NP (Noun Phrase): Sequences of determiners (DT), adjectives (JJ), and nouns (NN).\n",
        "   - VP (Verb Phrase): Verbs (VB) and their associated noun phrases (NP) or prepositional phrases (PP).\n",
        "\n",
        "5. **Create Chunk Parser:**\n",
        "   - Create a chunk parser using the defined regular expression-based grammar.\n",
        "\n",
        "6. **Apply Chunk Parser:**\n",
        "   - Apply the chunk parser to the POS-tagged sentence, creating a tree structure representing the chunks.\n",
        "\n",
        "7. **Visualize and Print Tree Structure:**\n",
        "   - Optionally, visualize the resulting tree structure.\n",
        "   - Print the tree structure using the `pretty_print()` method.\n",
        "\n",
        "This code demonstrates chunking based on a regular expression grammar, identifying and grouping noun phrases (NP) and verb phrases (VP) in the sample sentence. The resulting tree structure illustrates the identified chunks in the sentence."
      ],
      "metadata": {
        "id": "j6lZxNiZRqXC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ib87wC-1oeNR",
        "outputId": "041d199a-ef8b-4a73-8f32-eac06ab0ccd1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Package treebank is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                               S                                              \n",
            "    ___________________________|__________________________________________     \n",
            "   |     |            NP               NP      NP            NP           NP  \n",
            "   |     |     _______|________        |       |        _____|_____       |    \n",
            "over/IN ./. The/DT quick/JJ brown/NN fox/NN jumps/NN the/DT     lazy/NN dog/NN\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk import RegexpParser\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import treebank\n",
        "\n",
        "# Download the NLTK data (you only need to do this once)\n",
        "nltk.download('punkt')\n",
        "nltk.download('treebank')\n",
        "\n",
        "# Load a pre-trained POS tagger\n",
        "tagged_sentences = treebank.tagged_sents()\n",
        "train_data = tagged_sentences[:3000]\n",
        "pos_tagger = nltk.DefaultTagger('NN')  # Default tagger for unknown words\n",
        "pos_tagger = nltk.UnigramTagger(train_data, backoff=pos_tagger)\n",
        "\n",
        "# Define a sample sentence\n",
        "sample_sentence = \"The quick brown fox jumps over the lazy dog.\"\n",
        "\n",
        "# Tokenize and tag the sample sentence\n",
        "tokens = word_tokenize(sample_sentence)\n",
        "pos_tags = pos_tagger.tag(tokens)\n",
        "\n",
        "# Define a regular expression-based chunk grammar\n",
        "chunk_grammar = r\"\"\"\n",
        "    NP: {<DT>?<JJ>*<NN>}   # Chunk sequences of DT, JJ, and NN\n",
        "    VP: {<VB.*><NP|PP>*}   # Chunk verbs and their arguments\n",
        "\"\"\"\n",
        "\n",
        "# Create a chunk parser using the regular expression-based grammar\n",
        "chunk_parser = RegexpParser(chunk_grammar)\n",
        "\n",
        "# Apply the chunk parser to the POS-tagged sentence\n",
        "tree = chunk_parser.parse(pos_tags)\n",
        "\n",
        "# Visualize the resulting tree (optional)\n",
        "\n",
        "# Print the tree structure\n",
        "tree.pretty_print()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ATXFSAR2orEp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}