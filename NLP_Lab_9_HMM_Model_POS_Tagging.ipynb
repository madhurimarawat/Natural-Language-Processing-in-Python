{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Experiment 9\n",
        "## Implement HMM for POS tagging."
      ],
      "metadata": {
        "id": "i8UXUNX8P_hp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part-of-Speech (POS) Tagging and Hidden Markov Model (HMM) Overview:**\n",
        "\n",
        "1. **Part-of-Speech (POS) Tagging:**\n",
        "    - *Definition:* A natural language processing task that involves assigning a specific grammatical category (such as noun, verb, adjective) to each word in a sentence.\n",
        "    - *Purpose:* Enables linguistic analysis, information retrieval, and aids in various language processing applications.\n",
        "    - *Challenges:* Ambiguities and context dependencies pose challenges in accurately determining the correct POS for each word.\n",
        "\n",
        "2. **Hidden Markov Model (HMM):**\n",
        "    - *Definition:* A statistical model representing a system where the states are hidden but emit observable symbols.\n",
        "    - *Components:*\n",
        "        - *States:* Hidden states representing underlying structures.\n",
        "        - *Observations:* Observable symbols emitted by each state.\n",
        "        - *Transitions:* Probabilities of moving from one state to another.\n",
        "        - *Emissions:* Probabilities of emitting specific symbols from each state.\n",
        "    - *Application in POS Tagging:* HMMs are used to model the sequence of POS tags in a sentence. States represent POS tags, and emissions correspond to observed words.\n",
        "    - *Training:* Parameters (transitions and emissions probabilities) are learned from annotated training data, enabling the model to predict POS tags for unseen sentences.\n",
        "\n",
        "3. **POS Tagging with HMM:**\n",
        "    - *Modeling:* In HMM-based POS tagging, states represent different POS tags, transitions model the likelihood of moving from one tag to another, and emissions capture the probability of observing a word given a POS tag.\n",
        "    - *Viterbi Algorithm:* Employed to find the most likely sequence of POS tags for a given sequence of words, utilizing the calculated probabilities of transitions and emissions.\n",
        "    - *Example:* Given a sentence, the HMM calculates the most probable sequence of POS tags, aiding in accurate grammatical categorization.\n",
        "\n",
        "4. **Limitations:**\n",
        "    - *Sensitivity to Training Data:* HMM-based POS tagging may be sensitive to the quality and quantity of annotated training data.\n",
        "    - *Word Ambiguity:* The model may struggle with word ambiguity and context-dependent meanings.\n",
        "\n",
        "In summary, POS tagging with HMM involves using a statistical model to predict the sequence of grammatical categories for a given sequence of words, leveraging the principles of Hidden Markov Models to capture the underlying structure of language."
      ],
      "metadata": {
        "id": "5enCg36zQPs1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Explanation of the Code\n",
        "\n",
        "**Hidden Markov Model (HMM) POS Tagging with NLTK Code Explanation:**\n",
        "\n",
        "\n",
        "1. **Import Libraries:**\n",
        "   - `import nltk`: Import the Natural Language Toolkit (NLTK).\n",
        "   - `from nltk.tag import hmm`: Import the HMM module for POS tagging.\n",
        "   - `from nltk.corpus import treebank`: Import the Penn Treebank corpus.\n",
        "\n",
        "2. **Download NLTK Data:**\n",
        "   - `nltk.download('punkt')`: Download NLTK data for tokenization.\n",
        "   - `nltk.download('treebank')`: Download the Penn Treebank corpus.\n",
        "\n",
        "3. **Get Tagged Sentences:**\n",
        "   - `tagged_sentences = treebank.tagged_sents()`: Retrieve tagged sentences from the Penn Treebank corpus.\n",
        "\n",
        "4. **Split Data:**\n",
        "   - `train_data = tagged_sentences[:3000]`: Use the first 3000 sentences for training.\n",
        "   - `test_data = tagged_sentences[3000:]`: Use the remaining sentences for testing.\n",
        "\n",
        "5. **Train HMM Model:**\n",
        "   - `trainer = hmm.HiddenMarkovModelTrainer()`: Initialize an HMM trainer.\n",
        "   - `hmm_model = trainer.train(train_data)`: Train the HMM model using the training data.\n",
        "\n",
        "6. **Evaluate Model:**\n",
        "   - `accuracy = hmm_model.evaluate(test_data)`: Evaluate the model on the test data and calculate accuracy.\n",
        "   - `print(f\"Accuracy: {accuracy * 100:.2f}%\")`: Print the accuracy of the trained model.\n",
        "\n",
        "7. **Test Model on Sample Sentence:**\n",
        "   - `sample_sentence = \"This is a sample sentence.\"`: Define a sample sentence.\n",
        "   - `sample_tokens = nltk.word_tokenize(sample_sentence)`: Tokenize the sample sentence.\n",
        "   - `predicted_tags = hmm_model.tag(sample_tokens)`: Use the trained model to predict POS tags for the sample sentence.\n",
        "   - `print(\"Predicted POS Tags:\", predicted_tags)`: Print the predicted POS tags for the sample sentence."
      ],
      "metadata": {
        "id": "C9Sx_4FtQXGk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tftKPxUontry",
        "outputId": "64986198-6b7b-4706-b939-056f6607323b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Package treebank is already up-to-date!\n",
            "<ipython-input-4-e1cc2dd8b2f7>:21: DeprecationWarning: \n",
            "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
            "  instead.\n",
            "  accuracy = hmm_model.evaluate(test_data)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 36.84%\n",
            "Predicted POS Tags: [('This', 'DT'), ('is', 'VBZ'), ('a', 'DT'), ('sample', 'NNP'), ('sentence', 'NNP'), ('.', 'NNP')]\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.tag import hmm\n",
        "from nltk.corpus import treebank\n",
        "\n",
        "# Download the NLTK data (you only need to do this once)\n",
        "nltk.download('punkt')\n",
        "nltk.download('treebank')\n",
        "\n",
        "# Get tagged sentences from the Penn Treebank corpus\n",
        "tagged_sentences = treebank.tagged_sents()\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "train_data = tagged_sentences[:3000]\n",
        "test_data = tagged_sentences[3000:]\n",
        "\n",
        "# Train the HMM model\n",
        "trainer = hmm.HiddenMarkovModelTrainer()\n",
        "hmm_model = trainer.train(train_data)\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "accuracy = hmm_model.evaluate(test_data)\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# Test the model on a sample sentence\n",
        "sample_sentence = \"This is a sample sentence.\"\n",
        "sample_tokens = nltk.word_tokenize(sample_sentence)\n",
        "predicted_tags = hmm_model.tag(sample_tokens)\n",
        "print(\"Predicted POS Tags:\", predicted_tags)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tagged_sentences)"
      ],
      "metadata": {
        "id": "xh-tm-0Ynu9Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7536699a-3b11-4873-828f-194d014f318c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[('Pierre', 'NNP'), ('Vinken', 'NNP'), (',', ','), ('61', 'CD'), ('years', 'NNS'), ('old', 'JJ'), (',', ','), ('will', 'MD'), ('join', 'VB'), ('the', 'DT'), ('board', 'NN'), ('as', 'IN'), ('a', 'DT'), ('nonexecutive', 'JJ'), ('director', 'NN'), ('Nov.', 'NNP'), ('29', 'CD'), ('.', '.')], [('Mr.', 'NNP'), ('Vinken', 'NNP'), ('is', 'VBZ'), ('chairman', 'NN'), ('of', 'IN'), ('Elsevier', 'NNP'), ('N.V.', 'NNP'), (',', ','), ('the', 'DT'), ('Dutch', 'NNP'), ('publishing', 'VBG'), ('group', 'NN'), ('.', '.')], ...]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9bnGoz7Pbru1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}